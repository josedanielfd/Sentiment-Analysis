{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"new_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 2967\n"
     ]
    }
   ],
   "source": [
    "#Creating document term matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf_vectorizer = CountVectorizer(max_df=0.9,\n",
    "                                min_df=20,\n",
    "                                stop_words='english')\n",
    "tf_master = tf_vectorizer.fit_transform(df['text'])\n",
    "print(\"Vocabulary Size:\",tf_master.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating 1/0 label for \"sentiment\"\n",
    "\n",
    "def f(row):\n",
    "    if row['stars'] == 5 or row['stars'] == 4:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "df['labels'] = df.apply(f,axis=1)\n",
    "labels = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shoun\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Training test split\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "tf_master, labels, test_size = 0.25, random_state = 95828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Building an unpruned decision tree\n",
    "clf1 = DecisionTreeClassifier(criterion=\"entropy\",random_state=95825)\n",
    "clf1.fit(X_train,y_train)\n",
    "ypred_train = clf1.predict(X_train)\n",
    "ypred_test = clf1.predict(X_test)\n",
    "print(\"Training Accuracy: \",str(accuracy_score(y_train,ypred_train)))\n",
    "print(\"Test Accuracy: \",str(accuracy_score(y_test,ypred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 40\n",
      "Cross Validation Score: 0.772928808531\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "num_folds = 5\n",
    "fold_scores=[]\n",
    "param_values = np.arange(5,90,5)\n",
    "arg_max = None\n",
    "max_cross_val_score = -np.inf\n",
    "for C in param_values:\n",
    "    nums=[]\n",
    "    #print(\"C = \" + str(C))\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\",max_depth=C,random_state=95825)\n",
    "    cv_results = cross_validate(clf, X_train, y_train,cv=num_folds ,return_train_score=False)\n",
    "    nums.append(list(cv_results['test_score']))\n",
    "    fold_scores.append(np.mean(nums))\n",
    "    \n",
    "    cross_val_score = np.mean(nums)\n",
    "    if cross_val_score > max_cross_val_score:\n",
    "            max_cross_val_score = cross_val_score\n",
    "            arg_max = C\n",
    "\n",
    "\n",
    "best_C = arg_max\n",
    "print(\"Best C:\",best_C)\n",
    "print(\"Cross Validation Score:\",max_cross_val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9676\n",
      "Test Accuracy:  0.7664\n"
     ]
    }
   ],
   "source": [
    "#Using best hyperparameter to predict test accuracy\n",
    "\n",
    "clf2 = DecisionTreeClassifier(criterion=\"entropy\",max_depth=best_C,random_state=95825)\n",
    "clf2.fit(X_train,y_train)\n",
    "ypred_train = clf2.predict(X_train)\n",
    "ypred_test = clf2.predict(X_test)\n",
    "print(\"Training Accuracy: \",str(accuracy_score(y_train,ypred_train)))\n",
    "print(\"Test Accuracy: \",str(accuracy_score(y_test,ypred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869733333333\n",
      "best depth is :  {'base_estimator__max_depth': 80}\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf3 = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "num_trees = 100\n",
    "m = int (0.2 *tf_master.shape[1])\n",
    "model = BaggingClassifier(base_estimator=clf3, n_estimators=num_trees, max_features = m, random_state =95828 )\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "param_grid = [{'base_estimator__max_depth':np.arange(5,90,5)}]\n",
    "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_)\n",
    "print(\"best depth is : \",grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9996\n",
      "Test Accuracy:  0.8512\n"
     ]
    }
   ],
   "source": [
    "#RF on test data with best depth\n",
    "\n",
    "clf4 = DecisionTreeClassifier(criterion=\"entropy\",max_depth=grid.best_params_)\n",
    "num_trees = 100\n",
    "m = int (0.2 *tf_master.shape[1])\n",
    "\n",
    "model_new = BaggingClassifier(base_estimator=clf4, n_estimators=num_trees, max_features = m, random_state =95828 )\n",
    "model_new = model.fit(X_train, y_train)\n",
    "ypred_train = model_new.predict(X_train)\n",
    "ypred_test = model_new.predict(X_test)\n",
    "print(\"Training Accuracy: \",str(accuracy_score(y_train,ypred_train)))\n",
    "print(\"Test Accuracy: \",str(accuracy_score(y_test,ypred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8436\n"
     ]
    }
   ],
   "source": [
    "#Unregularized Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(penalty='l1',C=1e10)\n",
    "LogReg.fit(X_train, y_train)\n",
    "ypred_train = LogReg.predict(X_train)\n",
    "ypred_test = LogReg.predict(X_test)\n",
    "print(\"Training Accuracy: \",str(accuracy_score(y_train,ypred_train)))\n",
    "print(\"Test Accuracy: \",str(accuracy_score(y_test,ypred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.04\n",
      "C = 0.0905263157895\n",
      "C = 0.141052631579\n",
      "C = 0.191578947368\n",
      "C = 0.242105263158\n",
      "C = 0.292631578947\n",
      "C = 0.343157894737\n",
      "C = 0.393684210526\n",
      "C = 0.444210526316\n",
      "C = 0.494736842105\n",
      "C = 0.545263157895\n",
      "C = 0.595789473684\n",
      "C = 0.646315789474\n",
      "C = 0.696842105263\n",
      "C = 0.747368421053\n",
      "C = 0.797894736842\n",
      "C = 0.848421052632\n",
      "C = 0.898947368421\n",
      "C = 0.949473684211\n",
      "C = 1.0\n",
      "Best C: 0.545263157895\n",
      "Cross Validation Score: 0.890668226964\n"
     ]
    }
   ],
   "source": [
    "#Regularized Logisitc Regression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "fold_scores=[]\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds)\n",
    "param_values = np.linspace(0.04,1,num=20)\n",
    "arg_max = None\n",
    "max_cross_val_score = -np.inf\n",
    "for C in param_values:\n",
    "    nums=[]\n",
    "    \n",
    "    print(\"C = \" + str(C))\n",
    "    clf = LogisticRegression(penalty='l1',C=C)        \n",
    "    cv_results = cross_validate(clf, X_train, y_train,cv=num_folds ,return_train_score=False)\n",
    "    nums.append(list(cv_results['test_score']))\n",
    "    fold_scores.append(np.mean(nums))\n",
    "    \n",
    "    cross_val_score = np.mean(nums)\n",
    "    if cross_val_score > max_cross_val_score:\n",
    "            max_cross_val_score = cross_val_score\n",
    "            arg_max = C\n",
    "\n",
    "\n",
    "best_C = arg_max\n",
    "print(\"Best C:\",best_C)\n",
    "print(\"Cross Validation Score:\",max_cross_val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.957733333333\n",
      "Test Accuracy:  0.8816\n"
     ]
    }
   ],
   "source": [
    "LogReg_regularized = LogisticRegression(penalty='l1',C=best_C,)\n",
    "LogReg_regularized.fit(X_train, y_train)\n",
    "ypred_train = LogReg_regularized.predict(X_train)\n",
    "ypred_test = LogReg_regularized.predict(X_test)\n",
    "print(\"Training Accuracy: \",str(accuracy_score(y_train,ypred_train)))\n",
    "print(\"Test Accuracy: \",str(accuracy_score(y_test,ypred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0001\n",
      "C = 0.000464158883361\n",
      "C = 0.00215443469003\n",
      "C = 0.01\n",
      "C = 0.0464158883361\n",
      "C = 0.215443469003\n",
      "C = 1.0\n",
      "C = 4.64158883361\n",
      "C = 21.5443469003\n",
      "C = 100.0\n",
      "Best C: 0.01\n",
      "Cross Validation Score: 0.897201829156\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "fold_scores=[]\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds)\n",
    "param_values = np.logspace(-4, 2, 10)\n",
    "arg_max = None\n",
    "max_cross_val_score = -np.inf\n",
    "for C in param_values:\n",
    "    nums=[]\n",
    "    \n",
    "    print(\"C = \" + str(C))\n",
    "    clf = svm.LinearSVC(C=C)\n",
    "    cv_results = cross_validate(clf, X_train, y_train,cv=num_folds ,return_train_score=False)\n",
    "    nums.append(list(cv_results['test_score']))\n",
    "    fold_scores.append(np.mean(nums))\n",
    "    \n",
    "    cross_val_score = np.mean(nums)\n",
    "    if cross_val_score > max_cross_val_score:\n",
    "            max_cross_val_score = cross_val_score\n",
    "            arg_max = C\n",
    "\n",
    "\n",
    "best_C = arg_max\n",
    "print(\"Best C:\",best_C)\n",
    "print(\"Cross Validation Score:\",max_cross_val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.999333333333\n",
      "Test Accuracy:  0.844\n"
     ]
    }
   ],
   "source": [
    "clf_SVM = svm.LinearSVC(C=C)\n",
    "clf_SVM.fit(X_train, y_train)\n",
    "ypred_train = clf_SVM.predict(X_train)\n",
    "ypred_test = clf_SVM.predict(X_test)\n",
    "print(\"Training Accuracy: \",str(accuracy_score(y_train,ypred_train)))\n",
    "print(\"Test Accuracy: \",str(accuracy_score(y_test,ypred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1\n",
      "0.624129997391\n",
      "C = 3\n",
      "0.629466532741\n",
      "C = 5\n",
      "0.633327245331\n",
      "C = 7\n",
      "0.62772973268\n",
      "C = 9\n",
      "0.620528574102\n",
      "C = 11\n",
      "0.613860927227\n",
      "Best C: 5\n",
      "Cross Validation Score: 0.633327245331\n"
     ]
    }
   ],
   "source": [
    "# KNN \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "fold_scores=[]\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds)\n",
    "param_values = [1,3,5,7,9,11]\n",
    "arg_max = None\n",
    "max_cross_val_score = -np.inf\n",
    "for C in param_values:\n",
    "    nums=[]\n",
    "    \n",
    "    print(\"C = \" + str(C))\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=C)\n",
    "    cv_results = cross_validate(knn_model, X_train, y_train,cv=num_folds ,return_train_score=False)\n",
    "    nums.append(list(cv_results['test_score']))\n",
    "    fold_scores.append(np.mean(nums))\n",
    "    \n",
    "    cross_val_score = np.mean(nums)\n",
    "    print(cross_val_score)\n",
    "    if cross_val_score > max_cross_val_score:\n",
    "            max_cross_val_score = cross_val_score\n",
    "            arg_max = C\n",
    "\n",
    "\n",
    "best_C = arg_max\n",
    "print(\"Best C:\",best_C)\n",
    "print(\"Cross Validation Score:\",max_cross_val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7628\n",
      "Test Accuracy:  0.6188\n"
     ]
    }
   ],
   "source": [
    "clf_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_KNN.fit(X_train, y_train)\n",
    "ypred_train = clf_KNN.predict(X_train)\n",
    "ypred_test = clf_KNN.predict(X_test)\n",
    "print(\"Training Accuracy: \",str(accuracy_score(y_train,ypred_train)))\n",
    "print(\"Test Accuracy: \",str(accuracy_score(y_test,ypred_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
